from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
y_test_binario = (y_test == 1).astype(int)
fpr, tpr, thresholds = roc_curve(y_test_binario, y_pred_probs)
plt.plot([0,1], [0,1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Regresión Logistica - Curva ROC")
plt.show()
y_test_binario
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
y_test_binario = (y_test == 1).astype(int)
fpr, tpr, thresholds = roc_curve(y_pred, y_pred_probs)
plt.plot([0,1], [0,1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Regresión Logistica - Curva ROC")
plt.show()
diabetes_df
diabetes_df
from sklearn.linear_model import LogisticRegression
diabetes_df = pd.read_csv("diabetes_clean.csv")
X = diabetes_df.drop("glucose", axis = 1).values
y = diabetes_df["glucose"].values
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,
random_state = 42)
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
import pandas as pd
diabetes_df = pd.read_csv("diabetes_clean.csv")
print(diabetes_df.head())
import pandas as pd
diabetes_df = pd.read_csv("diabetes_clean.csv")
print(diabetes_df)
import pandas as pd
diabetes_df = pd.read_csv("diabetes_clean.csv")
print(diabetes_df.head())
X = diabetes_df.drop("glucose", axis = 1).values
y = diabetes_df["glucose"].values
print(type(X), type(y))
X = diabetes_df.drop("glucose", axis = 1).values
y = diabetes_df["glucose"].values
print(type(X), type(y))
X
X = diabetes_df.drop("glucose", axis = 1).values
y = diabetes_df["glucose"].values
print(type(X), type(y))
y
from sklearn.linear_model import LogisticRegression
diabetes_df = pd.read_csv("diabetes_clean.csv")
X = diabetes_df.drop("glucose", axis = 1).values
y = diabetes_df["glucose"].values
#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,
#random_state = 42)
#logreg = LogisticRegression()
#logreg.fit(X_train, y_train)
#y_pred = logreg.predict(X_test)
from sklearn.linear_model import LogisticRegression
diabetes_df = pd.read_csv("diabetes_clean.csv")
X = diabetes_df.drop("glucose", axis = 1).values
y = diabetes_df["glucose"].values
X
#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,
#random_state = 42)
#logreg = LogisticRegression()
#logreg.fit(X_train, y_train)
#y_pred = logreg.predict(X_test)
from sklearn.linear_model import LogisticRegression
diabetes_df = pd.read_csv("diabetes_clean.csv")
X = diabetes_df.drop("glucose", axis = 1).values
y = diabetes_df["glucose"].values
y
#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,
#random_state = 42)
#logreg = LogisticRegression()
#logreg.fit(X_train, y_train)
#y_pred = logreg.predict(X_test)
from sklearn.linear_model import LogisticRegression
diabetes_df = pd.read_csv("diabetes_clean.csv")
X = diabetes_df.drop("diabetes", axis = 1).values
y = diabetes_df["diabetes"].values
y
#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,
#random_state = 42)
#logreg = LogisticRegression()
#logreg.fit(X_train, y_train)
#y_pred = logreg.predict(X_test)
from sklearn.linear_model import LogisticRegression
diabetes_df = pd.read_csv("diabetes_clean.csv")
X = diabetes_df.drop("diabetes", axis = 1).values
y = diabetes_df["diabetes"].values
X
#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,
#random_state = 42)
#logreg = LogisticRegression()
#logreg.fit(X_train, y_train)
#y_pred = logreg.predict(X_test)
from sklearn.linear_model import LogisticRegression
diabetes_df = pd.read_csv("diabetes_clean.csv")
X = diabetes_df.drop("diabetes", axis = 1).values
y = diabetes_df["diabetes"].values
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,
random_state = 42)
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
from sklearn.model_selection import train_test_split
X = churn_df[["total_day_charge", "total_eve_charge"]].values
y = churn_df[["churn"]].values
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,
random_state = 21, stratify = y)
from sklearn.linear_model import LogisticRegression
diabetes_df = pd.read_csv("diabetes_clean.csv")
from sklearn.model_selection import train_test_split
X = diabetes_df.drop("diabetes", axis = 1).values
y = diabetes_df["diabetes"].values
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
y_pred_probs = logreg.predict_proba(X_test)[:, 1]
print(y_pred_probs[3])
y_pred_probs = logreg.predict_proba(X_test)[:, 1]
print(y_pred_probs[0])
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
y_test_binario = (y_test == 1).astype(int)
fpr, tpr, thresholds = roc_curve(y_pred, y_pred_probs)
plt.plot([0,1], [0,1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Regresión Logistica - Curva ROC")
plt.show()
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)
plt.plot([0,1], [0,1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Regresión Logistica - Curva ROC")
plt.show()
X = diabetes_df.drop("glucose", axis = 1).values
y = diabetes_df["glucose"].values
print(type(X), type(y))
from sklearn.metrics import roc_curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)
plt.plot([0,1],[0,1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('Tasa de Falsos Positovos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC de Regresión Logística')
plt.show()
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_auc_score
print(roc_auc_score(y_test, y_pred_probs))
y_pred_probs = logreg.predict_proba(X_test)[:, 1]
print(y_pred_probs[:10])
# Matriz de confusión
print(confusion_matrix(y_test, y_pred))
# Matriz de confusión
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_pred))
# Matriz de confusión
from sklearn.metrics import confusion_matrix, classification_report
print(confusion_matrix(y_test, y_pred))
# Reporte de clasificación
print(classification_report(y_test, y_pred))
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import GridSearchCV
kf = KFold(n_split = 5, shuffle = True, random_state = 42)
param_grid = {"alpha": np.arange(0.0001,1,10),"solver": ["sag", "lsqr"]}
from sklearn.model_selection import GridSearchCV
import numpy as np
kf = KFold(n_splits = 5, shuffle = True, random_state = 42)
param_grid = {"alpha": np.arange(0.0001,1,10),"solver": ["sag", "lsqr"]}
from sklearn.model_selection import cross_val_score, KFold
# KFold: nos permite establecer una semilla, de manera que nuestros resultado sean
#        repetibles.
kf =  KFold(n_splits = 6, shuffle = True, random_state = 42)
reg = LinearRegression()
cv_results = cross_val_score(reg, X, y, cv = kf)
print(cv_results)
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score, KFold
import numpy as np
kf = KFold(n_splits = 5, shuffle = True, random_state = 42)
param_grid = {"alpha": np.arange(0.0001,1,10),"solver": ["sag", "lsqr"]}
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score, KFold
import numpy as np
kf = KFold(n_splits = 5, shuffle = True, random_state = 42)
param_grid = {"alpha": np.arange(0.0001,1,10),"solver": ["sag", "lsqr"]}
ridge = Ridge()
ridge_cv = GridSearchCV(ridge, param_grid, cv = kf)
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.linear_model import Ridge
import numpy as np
kf = KFold(n_splits = 5, shuffle = True, random_state = 42)
param_grid = {"alpha": np.arange(0.0001,1,10),"solver": ["sag", "lsqr"]}
ridge = Ridge()
ridge_cv = GridSearchCV(ridge, param_grid, cv = kf)
